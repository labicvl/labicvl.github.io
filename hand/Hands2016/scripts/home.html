<h2> Aims and Scope </h2>

<p>
For this workshop's second iteration, we will attempt to gather
researchers who work on hand detection and hand pose estimation
problems. Development of RGB-D sensors (Kinect, Asus, Intel Creative,
Leap Motion etc) and camera miniaturization (wearable cameras, smart
phones, ubiquitous computing) have opened the door to a whole new
range of technologies and applications which require detecting hands
and recognizing hand poses in a variety of scenarios. Most hand
tracking data sets and papers have been focused on simple near-range
front-on scenarios. This workshop attempts to move past this with the
goal of evaluating a "breadth of applications" including: sign
language recognition, desktop interaction, egocentric views, object
manipulations, far range and over-the-shoulder driver footage. 
</p>

<p>
In the spirit of Chalearn "looking at people" for body pose estimation
or Pascal VOC Challenge for object recognition, we aim at comparing
new and established methods for hand detection and pose estimation on
a standard and varied data set covering multiple scenarios and
settings. We release such a dataset and encourage participants to use
it for evaluation and to participate in the challenge associated with
this workshop. 
</p>

<p>
Our program will feature several high-quality invited talks, challenge
results, oral and poster presentations of research, and a panel
discussion to identify key research questions and highlight future
research directions. As we want to encourage cross-pollination of
ideas from related fields such as robotics, HCI, machine learning, and
computer vision, we invite submissions of theoretical and applied
papers in all areas covered by the workshop, including, but not
limited to: 
</p>

<h2 class="auto-style1">Topics of Interests</h2>
  <ul id="interest">
    <li> Hand detection </li>
    <li> Hand pose and gesture recognition  </li>
    <li> 3D articulated hand tracking </li>
    <li> Hand modelling and rendering </li>
    <li> Grasping and object manipulation </li>
    <li> Hand activity recognition </li>
    <li> Gesture interfaces </li>
    <li> Egocentric vision systems </li>
    <li> Structured prediction </li>
    <li> Applications of hand pose estimation in AR/VR </li>
    <li> Applications of hand pose estimation in robotics and
      haptics </li>
  </ul>  

<h2 class="auto-style1">Invited Speakers</h2>
  <ul id="photo">
    <li><a href="http://users.ics.forth.gr/~argyros/" target="_blank"><img src="images/speaker_antonis.argyros.jpg" height="200px"/><br/> <label>Prof. Antonis Argyros</label><label>ICS-FORTH, Greece</label></a></li>
    <li><a href="http://www.cs.cmu.edu/~deva/" target="_blank"><img src="images/speaker_deva.ramanan.jpg" height="200px"/><br/> <label>Prof. Deva Ramanan</label><label>Carnegie Mellon University</label></a></li>
    <li><a href="http://cvlabwww.epfl.ch/~lepetit/" target="_blank"><img src="images/speaker_vincent.lepetit.jpg" height="200px"/><br/> <label>Prof. Vincent Lepetit</label><label>TU Graz</label></a></li>
    <li><a href="http://jacobsschool.ucsd.edu/faculty/faculty_bios/index.sfe?fmp_recid=68" target="_blank"><img src="images/speaker_mohan.trivedi.jpg" height="200px"/><br/> <label>Prof. Mohan Trivedi</label><label>UCSD</label></a></li>
    <li><a href="http://research.microsoft.com/en-us/people/jamiesho/" target="_blank"><img src="images/speaker_jamie.shotton.jpg" height="200px"/><br/> <label>Dr. Jamie Shotton</label><label>Microsoft Research</label></a></li>
  </ul>  